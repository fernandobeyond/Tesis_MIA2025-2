{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b39fc3e",
   "metadata": {},
   "source": [
    "\n",
    "# Semana 07 — (LightGBM) Importancia de variables, Calibración y Curvas de Aprendizaje\n",
    "**Plantilla lista para entregar**: ranking de variables, calibración y curvas de aprendizaje con **LightGBM**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc288d",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Requisitos\n",
    "```bash\n",
    "pip install lightgbm scikit-learn matplotlib\n",
    "# opcional\n",
    "pip install shap\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuración\n",
    "from pathlib import Path\n",
    "DATA_PATH  = Path(\"/mnt/data/tu_dataset.csv\")\n",
    "TARGET_COL = \"label\"\n",
    "DROP_COLS  = []\n",
    "RANDOM_STATE = 42\n",
    "print(\"Datos:\", DATA_PATH, \"| Target:\", TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194d2fa",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Carga y preprocesamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39941d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"No encuentro '{TARGET_COL}'.\")\n",
    "\n",
    "if DROP_COLS:\n",
    "    df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "\n",
    "y = df[TARGET_COL].astype(int)\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "print(\"num:\", len(num_cols), \"cat:\", len(cat_cols))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                     (\"scaler\", StandardScaler(with_mean=False))])\n",
    "cat_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True))])\n",
    "\n",
    "preprocess = ColumnTransformer([(\"num\", num_pipe, num_cols),\n",
    "                                (\"cat\", cat_pipe, cat_cols)])\n",
    "\n",
    "base_clf = LGBMClassifier(\n",
    "    n_estimators=600, learning_rate=0.05, num_leaves=64,\n",
    "    subsample=0.8, colsample_bytree=0.8, class_weight=\"balanced\",\n",
    "    random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline([(\"prep\", preprocess), (\"clf\", base_clf)])\n",
    "pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91eedc",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Entrenamiento y métricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "proba_test = pipe.predict_proba(X_test)[:,1]\n",
    "pred_test = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, proba_test))\n",
    "print(\"PR  AUC:\", average_precision_score(y_test, proba_test))\n",
    "print(\"\\n\", classification_report(y_test, pred_test, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_test)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Matriz de confusión\")\n",
    "plt.colorbar()\n",
    "plt.xticks([0,1],[0,1]); plt.yticks([0,1],[0,1])\n",
    "plt.xlabel(\"Predicho\"); plt.ylabel(\"Real\")\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j,i,cm[i,j],ha=\"center\",va=\"center\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca44842f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Importancia de variables (modelo + Permutation Importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99985a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def get_feature_names(preprocess):\n",
    "    num_names = preprocess.named_transformers_[\"num\"].named_steps[\"imputer\"]                     .get_feature_names_out(preprocess.transformers_[0][2])\n",
    "    oh = preprocess.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "    cat_cols = preprocess.transformers_[1][2]\n",
    "    cat_names = oh.get_feature_names_out(cat_cols)\n",
    "    return np.concatenate([num_names, cat_names])\n",
    "\n",
    "preprocess.fit(X_train, y_train)\n",
    "feature_names = get_feature_names(preprocess)\n",
    "\n",
    "# Importancia del modelo\n",
    "X_train_t = preprocess.transform(X_train)\n",
    "model = pipe.named_steps[\"clf\"]\n",
    "model.fit(X_train_t, y_train)\n",
    "fi = pd.DataFrame({\"feature\": feature_names, \"importance\": model.feature_importances_})        .sort_values(\"importance\", ascending=False)\n",
    "display(fi.head(30))\n",
    "\n",
    "# Permutation Importance (test)\n",
    "perm = permutation_importance(pipe, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "perm_df = pd.DataFrame({\"feature\": feature_names,\n",
    "                        \"importance_mean\": perm.importances_mean,\n",
    "                        \"importance_std\": perm.importances_std})             .sort_values(\"importance_mean\", ascending=False)\n",
    "print(\"\\nTop 30 por Permutation Importance (test):\")\n",
    "display(perm_df.head(30))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "TOP_N = 20\n",
    "fig = plt.figure(figsize=(8, max(4, int(TOP_N*0.35))))\n",
    "plt.barh(perm_df[\"feature\"].head(TOP_N)[::-1], perm_df[\"importance_mean\"].head(TOP_N)[::-1])\n",
    "plt.title(f\"Permutation Importance (Top {TOP_N}) — Test\")\n",
    "plt.xlabel(\"Disminución promedio de la métrica\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e05785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Opcional) SHAP\n",
    "try:\n",
    "    import shap, matplotlib.pyplot as plt\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    X_test_t = preprocess.transform(X_test)\n",
    "    shap_values = explainer.shap_values(X_test_t)\n",
    "    shap.summary_plot(shap_values, X_test_t, feature_names=feature_names, show=False)\n",
    "    plt.tight_layout(); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"SHAP no disponible:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f0cc8",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Calibración (Brier, ECE, curvas de confiabilidad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f52100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "def expected_calibration_error(y_true, y_prob, n_bins=15):\n",
    "    y_true = np.asarray(y_true); y_prob = np.asarray(y_prob)\n",
    "    bins = np.linspace(0,1,n_bins+1); ece=0.0; total=len(y_true)\n",
    "    for i in range(n_bins):\n",
    "        l,r=bins[i],bins[i+1]\n",
    "        mask=(y_prob>=l)&(y_prob<(r if i<n_bins-1 else r))\n",
    "        if np.any(mask):\n",
    "            acc=y_true[mask].mean(); conf=y_prob[mask].mean()\n",
    "            ece += abs(acc-conf)*(mask.sum()/total)\n",
    "    return ece\n",
    "\n",
    "def plot_reliability(y_true, proba_dict, n_bins=15, title_suffix=\"\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.plot([0,1],[0,1],\"--\")\n",
    "    for name,p in proba_dict.items():\n",
    "        frac_pos, mean_pred = calibration_curve(y_true, p, n_bins=n_bins, strategy=\"uniform\")\n",
    "        plt.plot(mean_pred, frac_pos, marker=\"o\", label=name)\n",
    "    plt.xlabel(\"Probabilidad promedio por bin\"); plt.ylabel(\"Fracción de positivos\")\n",
    "    plt.title(f\"Curva de confiabilidad {title_suffix}\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "orig_brier = brier_score_loss(y_test, proba_test)\n",
    "orig_ece   = expected_calibration_error(y_test.values, proba_test, n_bins=15)\n",
    "print(f\"Brier (original): {orig_brier:.6f} | ECE (original): {orig_ece:.6f}\")\n",
    "\n",
    "cal_iso = CalibratedClassifierCV(pipe, method=\"isotonic\", cv=5).fit(X_train, y_train)\n",
    "cal_sig = CalibratedClassifierCV(pipe, method=\"sigmoid\",  cv=5).fit(X_train, y_train)\n",
    "\n",
    "proba_iso = cal_iso.predict_proba(X_test)[:,1]\n",
    "proba_sig = cal_sig.predict_proba(X_test)[:,1]\n",
    "\n",
    "iso_brier = brier_score_loss(y_test, proba_iso); iso_ece = expected_calibration_error(y_test.values, proba_iso, 15)\n",
    "sig_brier = brier_score_loss(y_test, proba_sig); sig_ece = expected_calibration_error(y_test.values, proba_sig, 15)\n",
    "print(f\"Brier (isotonic): {iso_brier:.6f} | ECE (isotonic): {iso_ece:.6f}\")\n",
    "print(f\"Brier (sigmoid):  {sig_brier:.6f} | ECE (sigmoid):  {sig_ece:.6f}\")\n",
    "\n",
    "plot_reliability(y_test.values, {\"Original\": proba_test, \"Isotonic\": proba_iso, \"Sigmoid\": proba_sig}, 15, \"— LightGBM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a558764",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Curvas de aprendizaje\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03abb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    pipe, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1,1.0,6), shuffle=True\n",
    ")\n",
    "train_mean, val_mean = train_scores.mean(axis=1), val_scores.mean(axis=1)\n",
    "train_std,  val_std  = train_scores.std(axis=1),  val_scores.std(axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2)\n",
    "plt.fill_between(train_sizes, val_mean-val_std,     val_mean+val_std,     alpha=0.2)\n",
    "plt.plot(train_sizes, train_mean, marker=\"o\", label=\"Entrenamiento (AUC)\")\n",
    "plt.plot(train_sizes, val_mean,   marker=\"o\", label=\"Validación (AUC)\")\n",
    "plt.xlabel(\"Tamaño de entrenamiento\"); plt.ylabel(\"ROC AUC\"); plt.title(\"Curvas de aprendizaje — LightGBM\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
