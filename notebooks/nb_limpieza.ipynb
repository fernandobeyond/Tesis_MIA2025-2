{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f53f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87b1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al dataset crudo\n",
    "RAW_DATASET_PATH = \"../data/raw/ddos_final2.csv\"\n",
    "\n",
    "# Ruta donde se guardará el dataset limpio\n",
    "CLEANED_DATASET_PATH = \"../data/processed/ddos_findef.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d1ee0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurando rutas de entrada y salida...\n",
      "   Directorio de salida: ../data/processed\n"
     ]
    }
   ],
   "source": [
    "print(\"Configurando rutas de entrada y salida...\")\n",
    "output_dir = Path(CLEANED_DATASET_PATH).parent\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"   Directorio de salida: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d948f7",
   "metadata": {},
   "source": [
    "Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6388cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando dataset desde: ../data/raw/ddos_final2.csv\n",
      "Dataset cargado exitosamente.\n",
      "Dimensiones iniciales: (2660377, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCargando dataset desde: {RAW_DATASET_PATH}\")\n",
    "try:\n",
    "    df = pd.read_csv(RAW_DATASET_PATH)\n",
    "    print(\"Dataset cargado exitosamente.\")\n",
    "    print(\"Dimensiones iniciales:\", df.shape)\n",
    "    # print(\"\\nPrimeras 5 filas del dataset crudo:\")\n",
    "    # print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: El archivo {RAW_DATASET_PATH} no fue encontrado. Verifica la ruta.\")\n",
    "    exit() # Detener la ejecución si no se puede cargar el archivo\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error inesperado al cargar el dataset: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01973c",
   "metadata": {},
   "source": [
    "Separación de Características (X) y Objetivo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7efdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Separando características y variable objetivo...\n",
      "   Variable objetivo 'y' creada.\n",
      "   19 columnas seleccionadas como características (X).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSeparando características y variable objetivo...\")\n",
    "# Crear variable objetivo binaria si 'Attack_Label' existe\n",
    "if 'Attack_Label' in df.columns:\n",
    "    df[\"y\"] = (df[\"Attack_Label\"].astype(str) != \"BENIGN\").astype(int)\n",
    "    print(\"   Variable objetivo 'y' creada.\")\n",
    "    feature_cols = [c for c in df.columns if c not in [\"Attack_Label\", \"y\"]]\n",
    "    y = df[\"y\"].copy()\n",
    "else:\n",
    "    print(\"   Advertencia: Columna 'Attack_Label' no encontrada. Se procesarán todas las columnas como características.\")\n",
    "    feature_cols = df.columns.tolist()\n",
    "    y = None # No hay variable objetivo definida explícitamente\n",
    "\n",
    "# Seleccionar solo las características\n",
    "X = df[feature_cols].copy()\n",
    "print(f\"   {len(feature_cols)} columnas seleccionadas como características (X).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf649bbb",
   "metadata": {},
   "source": [
    "Saneamiento y Limpieza de Datos (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cefb560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1: Reemplazando valores infinitos (inf) por NaN...\n",
      "   4126 valores infinitos reemplazados por NaN. Infinitos restantes: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Reemplazar valores infinitos (inf, -inf) por NaN\n",
    "print(\"Paso 1: Reemplazando valores infinitos (inf) por NaN...\")\n",
    "numeric_cols_only = X.select_dtypes(include=np.number).columns # Select only numeric columns for inf check\n",
    "initial_inf_count = np.isinf(X[numeric_cols_only].values).sum() # Use .values for direct numpy operation\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "final_inf_count = np.isinf(X[numeric_cols_only].values).sum()\n",
    "print(f\"   {initial_inf_count} valores infinitos reemplazados por NaN. Infinitos restantes: {final_inf_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd6779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paso 2: Imputando NaNs específicos con 0...\n",
      "   Rellenando 2732 NaNs en la columna 'Flow Bytes/s' con el valor lógico 0.\n",
      "   Rellenando 2732 NaNs en la columna 'Flow Packets/s' con el valor lógico 0.\n",
      "   Resumen Paso 2 (NaNs):\n",
      "     'Flow Bytes/s': Antes=2732, Después=0\n",
      "     'Flow Packets/s': Antes=2732, Después=0\n"
     ]
    }
   ],
   "source": [
    "# 2. Imputación Específica para columnas problemáticas (Flow Bytes/s, Flow Packets/s)\n",
    "print(\"\\nPaso 2: Imputando NaNs específicos con 0...\")\n",
    "problem_cols = ['Flow Bytes/s', 'Flow Packets/s']\n",
    "nan_before_step2 = {}\n",
    "nan_after_step2 = {}\n",
    "for col in problem_cols:\n",
    "    if col in X.columns:\n",
    "        nan_before_step2[col] = X[col].isnull().sum()\n",
    "        if X[col].isnull().any(): # Solo rellenar si hay NaNs\n",
    "             print(f\"   Rellenando {nan_before_step2[col]} NaNs en la columna '{col}' con el valor lógico 0.\")\n",
    "             X[col] = X[col].fillna(0)\n",
    "             nan_after_step2[col] = X[col].isnull().sum()\n",
    "        else:\n",
    "             print(f\"   Columna '{col}' no contiene NaNs, no se necesita rellenar.\")\n",
    "             nan_after_step2[col] = 0\n",
    "# Imprimir resumen del paso 2\n",
    "print(\"   Resumen Paso 2 (NaNs):\")\n",
    "for col in problem_cols:\n",
    "     if col in nan_before_step2:\n",
    "        print(f\"     '{col}': Antes={nan_before_step2[col]}, Después={nan_after_step2[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a03cb670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paso 3: Imputando cualquier otro NaN numérico con la mediana...\n",
      "   No se encontraron otros NaNs numéricos para rellenar con mediana.\n"
     ]
    }
   ],
   "source": [
    "# 3. Imputación General con la mediana para CUALQUIER OTRO NaN restante en columnas NUMÉRICAS\n",
    "print(\"\\nPaso 3: Imputando cualquier otro NaN numérico con la mediana...\")\n",
    "numeric_cols = X.select_dtypes(include=np.number).columns\n",
    "nan_before_step3 = X[numeric_cols].isnull().sum().sum() - sum(nan_after_step2.get(col, 0) for col in problem_cols if col in X.columns) # Subtract NaNs already handled\n",
    "\n",
    "if nan_before_step3 > 0:\n",
    "    print(f\"   Calculando medianas para columnas con {nan_before_step3} NaNs restantes...\")\n",
    "    # Calculate medians only for columns that still have NaNs after step 2\n",
    "    cols_with_nan = X[numeric_cols].isnull().any()\n",
    "    cols_to_fill = cols_with_nan[cols_with_nan].index\n",
    "    if not cols_to_fill.empty:\n",
    "        medians = X[cols_to_fill].median()\n",
    "        # print(f\"   Medianas calculadas: {medians.to_dict()}\") # Opcional: ver medianas\n",
    "        X.fillna(medians, inplace=True) # Rellena solo donde X tiene NaN, usando las medianas correspondientes\n",
    "        print(f\"   {nan_before_step3} NaNs numéricos rellenados con medianas.\")\n",
    "    else:\n",
    "        print(\"   No se encontraron columnas adicionales con NaNs para rellenar.\")\n",
    "\n",
    "else:\n",
    "    print(\"   No se encontraron otros NaNs numéricos para rellenar con mediana.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6fec422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paso 4: Verificando NaNs restantes...\n",
      "¡Verificación de NaN exitosa! No quedan valores NaN en X.\n",
      "\n",
      "Paso 5: Reemplazando valores negativos específicos con 0...\n",
      "   En 'Init_Win_bytes_forward', 919278 valores negativos reemplazados. Negativos restantes: 0\n",
      "   En 'Init_Win_bytes_backward', 1339179 valores negativos reemplazados. Negativos restantes: 0\n",
      "\n",
      "--- Limpieza de datos completada --- \n"
     ]
    }
   ],
   "source": [
    "# 4. Verificación final de NaNs\n",
    "print(\"\\nPaso 4: Verificando NaNs restantes...\")\n",
    "nan_remaining = X.isnull().sum().sum()\n",
    "if nan_remaining > 0:\n",
    "    print(f\"ADVERTENCIA: Todavía quedan {nan_remaining} valores NaN después de la limpieza.\")\n",
    "    print(\"   Columnas con NaNs restantes:\")\n",
    "    print(X.isnull().sum()[X.isnull().sum() > 0])\n",
    "else:\n",
    "    print(\"¡Verificación de NaN exitosa! No quedan valores NaN en X.\")\n",
    "\n",
    "# 5. Saneamiento de valores negativos\n",
    "print(\"\\nPaso 5: Reemplazando valores negativos específicos con 0...\")\n",
    "negative_check_cols = [\"Init_Win_bytes_forward\", \"Init_Win_bytes_backward\"]\n",
    "for col in negative_check_cols:\n",
    "    if col in X.columns:\n",
    "        neg_count_before = (X[col] < 0).sum()\n",
    "        if neg_count_before > 0:\n",
    "            X.loc[X[col] < 0, col] = 0\n",
    "            neg_count_after = (X[col] < 0).sum()\n",
    "            print(f\"   En '{col}', {neg_count_before} valores negativos reemplazados. Negativos restantes: {neg_count_after}\")\n",
    "        else:\n",
    "            print(f\"   En '{col}', no se encontraron valores negativos.\")\n",
    "    else:\n",
    "        print(f\"   Columna '{col}' no encontrada para chequeo de negativos.\")\n",
    "\n",
    "print(\"\\n--- Limpieza de datos completada --- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ea157",
   "metadata": {},
   "source": [
    "Verificación Post-Limpieza (Opcional pero recomendado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3dad12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificación Post-Limpieza ---\n",
      "Verificando de nuevo si hay NaNs en X:\n",
      "   Total NaNs en X: 0\n",
      "\n",
      "Verificando de nuevo si hay Inf en X:\n",
      "   Total Infinitos en X: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Verificación Post-Limpieza ---\")\n",
    "print(\"Verificando de nuevo si hay NaNs en X:\")\n",
    "final_nan_check = X.isnull().sum().sum()\n",
    "print(f\"   Total NaNs en X: {final_nan_check}\")\n",
    "if final_nan_check > 0:\n",
    "     print(X.isnull().sum()[X.isnull().sum() > 0])\n",
    "\n",
    "\n",
    "print(\"\\nVerificando de nuevo si hay Inf en X:\")\n",
    "final_inf_check = np.isinf(X.select_dtypes(include=np.number).values).sum()\n",
    "print(f\"   Total Infinitos en X: {final_inf_check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f72b9f",
   "metadata": {},
   "source": [
    "Recombinación y Guardado del Dataset Limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77564669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Características (X) y objetivo (y) recombinados.\n",
      "\n",
      "Dimensiones del dataset limpio: (2660377, 20)\n"
     ]
    }
   ],
   "source": [
    "if y is not None:\n",
    "    # Asegurarse de que los índices coincidan si se han eliminado filas (aunque aquí no se eliminaron)\n",
    "    X_aligned = X.reindex(y.index) if X.index.equals(y.index) else X\n",
    "    df_cleaned = pd.concat([X_aligned, y.rename('y')], axis=1)\n",
    "    print(\"   Características (X) y objetivo (y) recombinados.\")\n",
    "    # Opcionalmente, puedes volver a añadir 'Attack_Label' si lo necesitas\n",
    "    # if 'Attack_Label' in df.columns:\n",
    "    #    df_cleaned = pd.concat([X_aligned, y.rename('y'), df['Attack_Label'].reindex(y.index)], axis=1)\n",
    "else:\n",
    "    df_cleaned = X.copy()\n",
    "    print(\"   Solo características (X) presentes.\")\n",
    "\n",
    "print(\"\\nDimensiones del dataset limpio:\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1e7a8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando dataset limpio en: ../data/processed/ddos_findef.csv\n",
      "✅ ¡Dataset limpio guardado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Guardar el dataframe limpio\n",
    "print(f\"Guardando dataset limpio en: {CLEANED_DATASET_PATH}\")\n",
    "try:\n",
    "    df_cleaned.to_csv(CLEANED_DATASET_PATH, index=False)\n",
    "    print(\"✅ ¡Dataset limpio guardado exitosamente!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al guardar el dataset limpio: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
